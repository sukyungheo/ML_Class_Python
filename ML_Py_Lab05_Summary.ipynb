{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "<pre>\n",
    "작은 데이터 셋일 경우, 기본 모델로서 좋고 설명하기 쉽다.\n",
    "</pre>\n",
    "\n",
    "### 선형모델(linear model)\n",
    "<pre>\n",
    "첫 번째로 시도할 알고리즘. 대용량 데이터셋 가능. 고차원 데이터에 가능\n",
    "</pre>\n",
    "\n",
    "### 나이브 베이즈(Naive Bayes)\n",
    "<pre>\n",
    "분류만 가능. 선형 모델보다 훨씬 빠름. 대용량 데이터셋과 고차원 데이터에 가능. \n",
    "선형 모델보다 덜 정확함.\n",
    "</pre>\n",
    "\n",
    "### 결정 트리(decision tree)\n",
    "<pre>\n",
    "매우 빠름. 데이터 스케일 조정이 필요 없다. 시각화하기 좋고 설명하기 쉽다.\n",
    "</pre>\n",
    "\n",
    "### 랜덤 포레스트(random forest)\n",
    "<pre>\n",
    "결정 트리 하나보다 거의 항상 좋은 성능을 냄. 매우 안정적이고 강력함. 데이터 스케일\n",
    "조정 필요 없음. 고차원 희소 데이터에는 잘 안 맞음.\n",
    "</pre>\n",
    "\n",
    "### 그래디언트 부스팅 결정 트리(gradient boosting decision tree)\n",
    "<pre>\n",
    "랜덤 포레스트보다 조금 더 성능이 좋다. 랜덤 포레스트보다 학습은 느리나 \n",
    "예측은 빠르고, 메모리를 조금 사용. 랜덤 포레스트보다 매개 변수 튜닝이 많이 필요함.\n",
    "</pre>\n",
    "\n",
    "### 서포트 벡터 머신\n",
    "<pre>\n",
    "비슷한 의미의 특성으로 이뤄진 중간 규모 데이터셋에 잘 맞는다.\n",
    "데이터 스케일 조정 필요. 매개변수에 민감.\n",
    "</pre>\n",
    "\n",
    "### 신경망(Neural Net)\n",
    "<pre>\n",
    "특별히 대용량 데이터셋에서 매우 복잡한 모델을 만들 수 있다. 매개 변수 선택과 데이터 스케일에 민감. 큰 모델은 학습이 오래 걸림.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 접근\n",
    "<pre>\n",
    "새로운 데이터 셋으로 작업할 때는 선형모델이나 나이브 베이즈 또는 최근접 이웃 분류기\n",
    "같은 <b>간단한 모델로 시작</b>해서 성능이 얼마나 나오는지 가늠해 보는 것이 좋다.\n",
    "\n",
    "<b>데이터를 충분히 이해한 뒤</b>에 랜덤 포레스트나 그래디언트 부스팅 결정 트리, SVM, 신경망 같은 복잡한 모델을 만들 수 있는 알고리즘을 고려한다.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98039216,  0.96078431,  1.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n",
      "0.980392156863\n",
      "0.959935897436\n",
      "0.966666666667\n",
      "0.966049382716\n",
      "0.966836734694\n",
      "0.96626984127\n",
      "0.974074074074\n"
     ]
    }
   ],
   "source": [
    "## 실습 1\n",
    "## IRIS 데이터 셋을 이용하여 k-fold 교차 검증을 수행해 보자. 평균값이 가장 높은 값을 얼마인가?\n",
    "for cvk in range(2,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    scores = cross_val_score(clf, iris.data, iris.target, cv=cvk).mean()\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보스턴 데이터 셋 이용한 회귀 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_extended_boston():\n",
    "    boston = load_boston()  # 데이터 셋 불러오기\n",
    "    X = boston.data         # 입력 데이터 \n",
    "    y = boston.target       # 목표 데이터 \n",
    "    \n",
    "    X = MinMaxScaler().fit_transform(boston.data)  # 입력 데이터 정규화\n",
    "    # PolynomialFeatures 적용전\n",
    "    print(X.shape, y.shape)\n",
    "    X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 나누기 & 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "(506, 104) (506,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_extended_boston()\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터 세트 점수, 테스트 데이터 세트 점수\n",
    "<pre>\n",
    "for문을 이용하여 가장 적합한 훈련/테스트 데이터 셋의 비율과 random_state를 찾아보자.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.79\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 세트 점수 : {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 데이터 세트 점수 : {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size 비율 : 0.1\n",
      "훈련 데이터 세트 점수 : 0.93\n",
      "테스트 데이터 세트 점수 : 0.86\n",
      "test size 비율 : 0.2\n",
      "훈련 데이터 세트 점수 : 0.94\n",
      "테스트 데이터 세트 점수 : 0.81\n",
      "test size 비율 : 0.3\n",
      "훈련 데이터 세트 점수 : 0.95\n",
      "테스트 데이터 세트 점수 : 0.67\n",
      "test size 비율 : 0.4\n",
      "훈련 데이터 세트 점수 : 0.95\n",
      "테스트 데이터 세트 점수 : 0.72\n",
      "test size 비율 : 0.5\n",
      "훈련 데이터 세트 점수 : 0.96\n",
      "테스트 데이터 세트 점수 : 0.72\n",
      "test size 비율 : 0.6\n",
      "훈련 데이터 세트 점수 : 0.97\n",
      "테스트 데이터 세트 점수 : 0.25\n",
      "test size 비율 : 0.7\n",
      "훈련 데이터 세트 점수 : 0.98\n",
      "테스트 데이터 세트 점수 : -1.22\n",
      "test size 비율 : 0.8\n",
      "훈련 데이터 세트 점수 : 1.00\n",
      "테스트 데이터 세트 점수 : -17.11\n",
      "test size 비율 : 0.9\n",
      "훈련 데이터 세트 점수 : 1.00\n",
      "테스트 데이터 세트 점수 : -0.62\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    rate = i / 10\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=rate, random_state=42)\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    print(\"test size 비율 : {:1}\".format(rate))\n",
    "    print(\"훈련 데이터 세트 점수 : {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "    print(\"테스트 데이터 세트 점수 : {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
